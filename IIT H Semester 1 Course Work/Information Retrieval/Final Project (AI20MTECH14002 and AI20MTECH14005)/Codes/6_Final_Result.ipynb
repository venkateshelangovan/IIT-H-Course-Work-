{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Result.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOmi0UJSbLn5"
      },
      "source": [
        "# Predicted Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he2WFOklZZRd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnnr9IQrZgdU"
      },
      "source": [
        "# Validation Data\n",
        "'''\n",
        "Loading Validation Data for which Coarse Grained Model \n",
        "(NonHostile vs Hostile Classification) predicted Hostile Class\n",
        "'''\n",
        "file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/hostile_validate_pred.xlsx'\n",
        "test_df = pd.read_excel(file)\n",
        "\n",
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "  text_labels = list(a['Labels Set'])\n",
        "\n",
        "  label = []\n",
        "  for i in text_labels:\n",
        "    if i=='hostile':\n",
        "        label.append(0)\n",
        "\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df\n",
        "\n",
        "test_data  = get_data(test_df)\n",
        "\n",
        "print(test_data[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um2aYOzrbabh"
      },
      "source": [
        "# Hostile ID Collection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHN-feglaTQS"
      },
      "source": [
        "# Collecting Hostile IDs from Validation Data\n",
        "\n",
        "data = test_data\n",
        "\n",
        "hos_ids = []\n",
        "for i in range(len(data)):\n",
        "  id = data['UID'][i]\n",
        "  hos_ids.append(id)\n",
        "\n",
        "hos_ids = np.array(hos_ids, dtype=np.int)\n",
        "np.save('Predicted_Hostile_ID_Task1.npy',hos_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1XcSlsPbixS"
      },
      "source": [
        "# Predicted Labels Loading (Fake, Hate, Offensive, Defamation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGYARfJRbKCB"
      },
      "source": [
        "d_lab = np.load('/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Final Task Data/Final_Defamation_validation_Pred_Label.npy', allow_pickle=True)\n",
        "f_lab = np.load('/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Final Task Data/Final_Fake_validation_Pred_Label.npy', allow_pickle=True)\n",
        "h_lab = np.load('/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Final Task Data/Final_Hate_validation_Pred_Label.npy', allow_pickle=True)\n",
        "o_lab = np.load('/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Final Task Data/Final_Offensive_validation_Pred_Label.npy', allow_pickle=True)\n",
        "hos_ids = np.load('/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Final Task Data/Predicted_Hostile_ID_Task1.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0eSzzsZcAPI"
      },
      "source": [
        "# Merging Labels to Asses Performance measurement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5CH0c26brAh"
      },
      "source": [
        "# Merging Predicted labels into a single numpy array\n",
        "# Reference: [non_hostile,defamation,fake,hate,offensive]\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "count = 0\n",
        "for i in range(1,812):\n",
        "  row = []\n",
        "  if i not in hos_ids:\n",
        "    row.append([1,0,0,0,0])\n",
        "  else:\n",
        "    alt_row = [0,0,0,0,0]\n",
        "    if d_lab[count]==1:\n",
        "      alt_row[1] = 1\n",
        "    if f_lab[count]==1:\n",
        "      alt_row[2] = 1\n",
        "    if h_lab[count]==1:\n",
        "      alt_row[3] = 1\n",
        "    if o_lab[count]==1:\n",
        "      alt_row[4] = 1\n",
        "    count += 1\n",
        "    row.append(alt_row)\n",
        "  predicted_labels.append(row)\n",
        "\n",
        "pred_lab = np.reshape(np.array(predicted_labels),(811,5)) # Final Predicted Labels\n",
        "np.save('Final_Pred_Labels_Validation.npy',pred_lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoxaPTAdcSPw"
      },
      "source": [
        "# Loading True Labels (811,5) and Predicted Labels (811,5) for Final Result Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfok1L51b_W4"
      },
      "source": [
        "y_true = np.load('/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Final Task Data/True_Validation_labels.npy', allow_pickle=True)\n",
        "y_pred = np.load('/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Final Task Data/Final_Pred_Labels_Validation.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjQmo3w6cdqh"
      },
      "source": [
        "# Computing Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSRn5MG5cbt6"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_true, y_pred, average='macro'))\n",
        "print(f1_score(y_true, y_pred, average='micro'))\n",
        "print(f1_score(y_true, y_pred, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xksjw8kCclP4"
      },
      "source": [
        "# Creating Final Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLC1RLkacgLh"
      },
      "source": [
        "# Reference: [non_hostile,defamation,fake,hate,offensive]\n",
        "labels = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  lab_text = []\n",
        "  idx = np.argwhere(y_pred[i]>0)\n",
        "  idx = idx.reshape(idx.shape[0],)\n",
        "  if idx.shape[0]==0:\n",
        "    lab_text.append('non_hostile')\n",
        "  else:\n",
        "    for j in idx:\n",
        "      if j==0:\n",
        "        lab_text.append('non-hostile')\n",
        "      if j==1:\n",
        "        lab_text.append('defamation')\n",
        "      if j==2:\n",
        "        lab_text.append('fake')\n",
        "      if j==3:\n",
        "        lab_text.append('hate')\n",
        "      if j==4:\n",
        "        lab_text.append('offensive')\n",
        "  labels.append(lab_text)\n",
        "\n",
        "def final_submission(label_list):\n",
        "  import csv\n",
        "  data = []\n",
        "  titles = ['Unique ID','Labels Set']\n",
        "  data.append(titles)\n",
        "  for i in range(len(label_list)):\n",
        "    row = []\n",
        "    row.append(i+1)\n",
        "    lab_text = ''\n",
        "    for j in range(len(label_list[i])):\n",
        "      lab_text += str(label_list[i][j])+','\n",
        "    lab_text = lab_text[:-1]+''\n",
        "    row.append(str(lab_text))\n",
        "    data.append(row)\n",
        "\n",
        "  file1 = \"answer.csv\"\n",
        "  with open(file1, 'w') as csvfile:  \n",
        "    csvwriter = csv.writer(csvfile)   \n",
        "    csvwriter.writerows(data)\n",
        "\n",
        "final_submission(labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}