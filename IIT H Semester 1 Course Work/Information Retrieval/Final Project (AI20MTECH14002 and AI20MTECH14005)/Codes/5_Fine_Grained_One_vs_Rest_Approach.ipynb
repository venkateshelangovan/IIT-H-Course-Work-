{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Grained One vs Rest Approach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2rj4jmOvJL"
      },
      "source": [
        "# Code Objective:\n",
        "\n",
        "*   mBERT Model for Fine Grained Evaluation\n",
        "*   Constructing Problem from Multilabel Classification to independent Binary Classification\n",
        "\n",
        "# Code Results:\n",
        "*   Accuracy - mBERT Model for Fake vs Non-Fake = 81.38 %\n",
        "*   Accuracy - mBERT Model for Hate vs Non-Hate = 77.12 %\n",
        "*   Accuracy - mBERT Model for Defamation vs Non-Defamation = 79.52 %\n",
        "*   Accuracy - mBERT Model for Offensive vs Non-Offensive = 69.68 %\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dWCw-Y5PuXQ"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvMlDjs63TBG"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ppFOaeJxHD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "from uuid import uuid4\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import glue_compute_metrics\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig, XLMRobertaForSequenceClassification\n",
        "\n",
        "print(\"GPU Torch Available = {}\".format(torch.cuda.is_available()))\n",
        "print(\"Torch Version = {}\".format(torch.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiO16rxYP0lF"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDZqu8NCXxeL"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlZhZHC9YG4a"
      },
      "source": [
        "'''\n",
        "Loading Dataset for Finegrained Multilabel Evaluation which has been transformed\n",
        "as multiple independent binary classification (One vs Rest Approach)\n",
        "'''\n",
        "\n",
        "dataset = 'Fake'             # Choosing Dataset to Load\n",
        "\n",
        "if dataset == 'Fake':\n",
        "  # Training Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/fake_train.xlsx'\n",
        "  train_df = pd.read_excel(file)\n",
        "  # Validation Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/fake_validate.xlsx'\n",
        "  test_df = pd.read_excel(file)\n",
        "  test_df\n",
        "\n",
        "elif dataset == 'Hate':\n",
        "  # Training Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/hate_train.xlsx'\n",
        "  train_df = pd.read_excel(file)\n",
        "  # Validation Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/hate_validate.xlsx'\n",
        "  test_df = pd.read_excel(file)\n",
        "  test_df\n",
        "\n",
        "elif dataset == 'Offensive':\n",
        "  # Training Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/offensive_train.xlsx'\n",
        "  train_df = pd.read_excel(file)\n",
        "  # Validation Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/offensive_validate.xlsx'\n",
        "  test_df = pd.read_excel(file)\n",
        "  test_df\n",
        "\n",
        "elif dataset == 'Defamation':\n",
        "  # Training Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/defamation_train.xlsx'\n",
        "  train_df = pd.read_excel(file)\n",
        "  # Validation Data\n",
        "  file = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Dataset/defamation_validate.xlsx'\n",
        "  test_df = pd.read_excel(file)\n",
        "  test_df\n",
        "\n",
        "else:\n",
        "  print('Choose Correct Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPD7q2_YM55"
      },
      "source": [
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "  text_labels = list(a['Labels Set'])\n",
        "\n",
        "  label = []\n",
        "  for i in text_labels:\n",
        "    if i=='non_offensive':\n",
        "        label.append(0)\n",
        "    elif i=='offensive':\n",
        "        label.append(1)\n",
        "    elif i=='non_fake':\n",
        "        label.append(0)\n",
        "    elif i=='fake':\n",
        "        label.append(1)\n",
        "    elif i=='non_hate':\n",
        "        label.append(0)\n",
        "    elif i=='hate':\n",
        "        label.append(1)\n",
        "    elif i=='non_defamation':\n",
        "        label.append(0)\n",
        "    elif i=='defamation':\n",
        "        label.append(1)\n",
        "\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df\n",
        "\n",
        "train_data = get_data(train_df)\n",
        "test_data  = get_data(test_df)\n",
        "\n",
        "print(train_data[0:3])\n",
        "print(test_data[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-LBlN9xStzh"
      },
      "source": [
        "# Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ALqUM9f5Qnx"
      },
      "source": [
        "# Choose and Load Model\n",
        "model_name = 'Bert'\n",
        "\n",
        "if (model_name == 'Bert'):\n",
        "  # Bert Parameters\n",
        "  config = BertConfig.from_pretrained('bert-base-multilingual-cased',num_labels=2)\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "  model = BertForSequenceClassification(config)\n",
        "elif (model_name == 'Roberta'):\n",
        "  # XLMRoberta Parameters\n",
        "  config = XLMRobertaConfig.from_pretrained('xlm-roberta-base',num_labels=2)\n",
        "  tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "  model = XLMRobertaForSequenceClassification(config)\n",
        "else:\n",
        "  print('Choose correct Model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xsy7ghkSvyf"
      },
      "source": [
        "# Data Preparation for Model Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf0ATRkF5LEx"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.sentence = dataframe.sentence\n",
        "        self.targets = self.data.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentence)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence1 = str(self.sentence[index])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(sentence1,\n",
        "                                            truncation=True,\n",
        "                                            add_special_tokens=True,\n",
        "                                            max_length=self.max_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_token_type_ids=True)\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "               }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDx-QxmX5Muc"
      },
      "source": [
        "# Dataset for Input into Model\n",
        "MAX_LEN = 128                                                 # Max Sequence Length\n",
        "training_set = CustomDataset(train_data, tokenizer, MAX_LEN)  # Training Set\n",
        "testing_set = CustomDataset(test_data, tokenizer, MAX_LEN)    # Validation Set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnQH2cqlTRoU"
      },
      "source": [
        "# Training and Evaluation Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ia34HohXuSU"
      },
      "source": [
        "# Device Mapping Select (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.cuda()\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(output_dir=\"./models/model_name\",\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  do_train=True,\n",
        "                                  do_eval=True,\n",
        "                                  per_device_train_batch_size=28,\n",
        "                                  per_device_eval_batch_size=28,\n",
        "                                  num_train_epochs=20,\n",
        "                                  logging_steps=100,\n",
        "                                  logging_first_step=True,\n",
        "                                  save_steps=0,\n",
        "                                  evaluate_during_training=True)\n",
        "\n",
        "# Metric for Performance Evaluation\n",
        "def compute_metrics(p):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return glue_compute_metrics(\"mnli\", preds, p.label_ids)\n",
        "\n",
        "# Trainer for training Model\n",
        "trainer = Trainer(model = model,\n",
        "                  args = training_args,\n",
        "                  train_dataset = training_set,\n",
        "                  eval_dataset = testing_set,\n",
        "                  compute_metrics = compute_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v84hu3rWXzz8"
      },
      "source": [
        "# Training Model\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRnlRPCkZ3-s"
      },
      "source": [
        "# Evaluation of Model on Validation Data\n",
        "trainer.evaluate(testing_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1639h8QPW0Z6"
      },
      "source": [
        "# Trained Model Save and Load for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8-c3xRdayNC"
      },
      "source": [
        "# Model Save\n",
        "model_save_path = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Weights/BERT_state_dict_offensive_'\n",
        "torch.save(model.state_dict(), model_save_path + str(uuid4())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjY2SE3nt6o-"
      },
      "source": [
        "# Model Load\n",
        "model_path = '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Weights/XLMR_state_dict_offensive_de181722-b72b-4ea0-9713-27769728db16.pth'\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOOA69dLXLUk"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpV2-snhjnR4"
      },
      "source": [
        "'''\n",
        "Load Model, predict on validation or test data and get labels for each dataset\n",
        "For 4 different datasets (Fake, Hate, Defamation, Offensive) \n",
        "we get 4 output numpy array of labels. \n",
        "'''\n",
        "\n",
        "# Prediction\n",
        "def prepare_features(seq_1, max_seq_length = 128, zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "    ## Tokenzine Input\n",
        "    tokens_a = tokenizer.tokenize(seq_1)\n",
        "\n",
        "    ## Truncate\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "    ## Initialize Tokens\n",
        "    tokens = []\n",
        "    if include_CLS_token:\n",
        "        tokens.append(tokenizer.cls_token)\n",
        "    ## Add Tokens and separators\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "\n",
        "    if include_SEP_token:\n",
        "        tokens.append(tokenizer.sep_token)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    ## Input Mask \n",
        "    input_mask = [1] * len(input_ids)\n",
        "    ## Zero-pad sequence lenght\n",
        "    if zero_pad:\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "    return torch.tensor(input_ids).unsqueeze(0), input_mask\n",
        "\n",
        "\n",
        "def predict(text):\n",
        "  model.eval()\n",
        "  input_feature, _ = prepare_features(text)\n",
        "  if torch.cuda.is_available():\n",
        "    input_feature = input_feature.cuda()\n",
        "  output = model(input_feature)[0]\n",
        "  _, pred_label = torch.max(output.data, 1)\n",
        "  prediction = pred_label[0].item()\n",
        "  if (prediction == 0):\n",
        "    return 'non_offensive',0\n",
        "  else:\n",
        "    return 'offensive',1\n",
        "\n",
        "data = test_data\n",
        "\n",
        "pred = []\n",
        "pred_lab = []\n",
        "for i in range(len(data)):\n",
        "  text = data['sentence'][i]\n",
        "  pred_text , pred_label = predict(text)\n",
        "  pred.append(pred_text)\n",
        "  pred_lab.append(pred_label)\n",
        "\n",
        "pred_lab = np.array(pred_lab, dtype=np.float)\n",
        "np.save('Final_Offensive_validation_Pred_Label.npy',pred_lab)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}